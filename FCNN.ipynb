{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FCNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMRXJt3GoafHFS78oOnAekQ"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Fully Conencted Neural Network\n",
        "This section models a Simple fully connected neural network"
      ],
      "metadata": {
        "id": "Pys1yBShXn3t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Downloading and extracting the CIFAR10 dataset"
      ],
      "metadata": {
        "id": "UMFqhBGlXvl0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown --id 1Y1vgzPvMeVcXSxDfOlCVia7wsU7p8M6g -O CIFAR10.tar.gz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UpN3CIzcm2Vs",
        "outputId": "550db42c-7306-401c-ea0a-6cc022e79fdf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gdown/cli.py:131: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  category=FutureWarning,\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1Y1vgzPvMeVcXSxDfOlCVia7wsU7p8M6g\n",
            "To: /content/CIFAR10.tar.gz\n",
            "100% 19.8M/19.8M [00:00<00:00, 61.5MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!tar xzf CIFAR10.tar.gz"
      ],
      "metadata": {
        "id": "YLPnvVngdsk0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Programming the model"
      ],
      "metadata": {
        "id": "fmvA2Gcydq1E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initial setup\n",
        "Configuring the network hyperparameters"
      ],
      "metadata": {
        "id": "g-1vPGE_X7oU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as pyplot\n",
        "import matplotlib.image as mplimage\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# Input data charecteristics:\n",
        "width = 32\n",
        "height = 32\n",
        "channels = 3\n",
        "n_train_samples = 20000\n",
        "n_test_samples = 4000\n",
        "n_classes = 4\n",
        "n_actual = 20000\n",
        "\n",
        "# Neural network charecteristics:\n",
        "layer_1 = 1024\n",
        "layer_2 = 16\n",
        "layer_3 = 4\n",
        "learning_rate = 0.3\n",
        "epochs = 40\n",
        "batch_size = 16"
      ],
      "metadata": {
        "id": "XIAEXaEedr59"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### read_imgs\n",
        "Loads the dataset into two sections train and test, each containing data in 4 categories of:\n",
        "- Aeroplane\n",
        "- Automobile\n",
        "- Bird\n",
        "- Cat"
      ],
      "metadata": {
        "id": "qkKIsnRJYGeL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_imgs(path):\n",
        "  i = 0\n",
        "  imgs = np.empty((n_train_samples, width, height, channels), dtype=np.uint8)\n",
        "  labels = np.empty((n_train_samples, n_classes, 1), dtype=int)\n",
        "\n",
        "  os.chdir(path + '/airplane')\n",
        "  for img in os.listdir(os.getcwd()):\n",
        "    imgs[i] = mplimage.imread(img)\n",
        "    labels[i] = [[1],\n",
        "                 [0],\n",
        "                 [0],\n",
        "                 [0]]\n",
        "    i += 1\n",
        "\n",
        "  os.chdir(path + '/automobile')\n",
        "  for img in os.listdir(os.getcwd()):\n",
        "    imgs[i] = mplimage.imread(img)\n",
        "    labels[i] = [[0],\n",
        "                 [1],\n",
        "                 [0],\n",
        "                 [0]]\n",
        "    i += 1\n",
        "\n",
        "  os.chdir(path + '/bird')\n",
        "  for img in os.listdir(os.getcwd()):\n",
        "    imgs[i] = mplimage.imread(img)\n",
        "    labels[i] = [[0],\n",
        "                 [0],\n",
        "                 [1],\n",
        "                 [0]]\n",
        "    i += 1\n",
        "\n",
        "  os.chdir(path + '/cat')\n",
        "  for img in os.listdir(os.getcwd()):\n",
        "    imgs[i] = mplimage.imread(img)\n",
        "    labels[i] = [[0],\n",
        "                 [0],\n",
        "                 [0],\n",
        "                 [1]]\n",
        "    i += 1\n",
        "\n",
        "  return imgs, labels"
      ],
      "metadata": {
        "id": "MStJouTYdwQw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### rgb2grey\n",
        "Greyscales the RGB input images"
      ],
      "metadata": {
        "id": "kt3wOXFkYe3q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def rgb2grey(rgb):\n",
        "  r, g, b = rgb[:, :, :, 0], rgb[:, :, :, 1], rgb[:, :, :, 2]\n",
        "  grey = 0.2989 * r + 0.5870 * g + 0.1140 * b\n",
        "  return grey"
      ],
      "metadata": {
        "id": "mhy4roTqdwdy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### normalise\n",
        "Normalises the input images"
      ],
      "metadata": {
        "id": "zsV8lxLzYmrV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def normalise(data):\n",
        "  return data / 255.0"
      ],
      "metadata": {
        "id": "s6fJjSJSdwmZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### shuffle_data\n",
        "Shuffles the input dataset"
      ],
      "metadata": {
        "id": "pLXZ1JdSYtM4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def shuffle_data(img_arr, label_arr):\n",
        "  p = np.random.permutation(len(img_arr))\n",
        "  return img_arr[p], label_arr[p]"
      ],
      "metadata": {
        "id": "lZ5nNlzsdwpR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### sigmoid and sigmoid_prime\n",
        "The activation function and its derivative"
      ],
      "metadata": {
        "id": "dSIsBk6nY0UM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(x):\n",
        "  return 1 / (1 + np.exp(-x))"
      ],
      "metadata": {
        "id": "Kjjshuv6eVL5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid_prime(x):\n",
        "  return sigmoid(x) * (1 - sigmoid(x))"
      ],
      "metadata": {
        "id": "AGg8kipJeZx3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### initialise_network\n",
        "Initialises the network weights and biases"
      ],
      "metadata": {
        "id": "fTtzUTShY_AV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def initialise_network():\n",
        "  l1w = np.random.normal(0, 1, (layer_2, layer_1))\n",
        "  l2w = np.random.normal(0, 1, (layer_2, layer_2))\n",
        "  l3w = np.random.normal(0, 1, (layer_3, layer_2))\n",
        "  l1b = np.zeros((layer_2, 1), dtype=float)\n",
        "  l2b = np.zeros((layer_2, 1), dtype=float)\n",
        "  l3b = np.zeros((layer_3, 1), dtype=float)\n",
        "  weights = [l1w, l2w, l3w]\n",
        "  biases = [l1b, l2b, l3b]\n",
        "  return weights, biases"
      ],
      "metadata": {
        "id": "75pe-TwWeZ5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### initialise_gradients\n",
        "Initialises the network weight and bias gradients"
      ],
      "metadata": {
        "id": "8vWiy3zTZHK-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def initialise_gradients():\n",
        "  l1gw = np.zeros((layer_2, layer_1), dtype=float)\n",
        "  l2gw = np.zeros((layer_2, layer_2), dtype=float)\n",
        "  l3gw = np.zeros((layer_3, layer_2), dtype=float)\n",
        "  l1gb = np.zeros((layer_2, 1), dtype=float)\n",
        "  l2gb = np.zeros((layer_2, 1), dtype=float)\n",
        "  l3gb = np.zeros((layer_3, 1), dtype=float)\n",
        "  grad_weights = [l1gw, l2gw, l3gw]\n",
        "  grad_biases = [l1gb, l2gb, l3gb]\n",
        "  return grad_weights, grad_biases"
      ],
      "metadata": {
        "id": "adiEOlLAeVWk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### feed_forward\n",
        "Computes the output for the current image given"
      ],
      "metadata": {
        "id": "6YJ8EjhcZMEk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def feed_forward(img, w, b):\n",
        "  z1 = w[0] @ img + b[0]\n",
        "  l1o = sigmoid(z1)\n",
        "  z2 = w[1] @ l1o + b[1]\n",
        "  l2o = sigmoid(z2)\n",
        "  z3 = w[2] @ l2o + b[2]\n",
        "  l3o = sigmoid(z3)\n",
        "  return [l1o, l2o, l3o], [z1, z2, z3]"
      ],
      "metadata": {
        "id": "ctKBa6-9eVf3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### back_propagate\n",
        "Uses backpropagation to get the weight and bias gradients"
      ],
      "metadata": {
        "id": "RCrZasekZThm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " def back_propagate(o, z, w, b, img, label):\n",
        "  grad_b2 = (2 * sigmoid_prime(z[2]) * (o[2] - label))\n",
        "  grad_w2 = grad_b2 @ np.transpose(o[1])\n",
        "  grad_o2 = np.transpose(w[2]) @ grad_b2\n",
        "\n",
        "  grad_b1 = sigmoid_prime(z[1]) * grad_o2\n",
        "  grad_w1 = grad_b1 @ np.transpose(o[0])\n",
        "  grad_o1 = np.transpose(w[1]) @ grad_b1\n",
        "\n",
        "  grad_b0 = sigmoid_prime(z[0]) * grad_o1\n",
        "  grad_w0 = grad_b0 @ np.transpose(img)\n",
        "  \n",
        "  return grad_w0, grad_b0, grad_w1, grad_b1, grad_w2, grad_b2 "
      ],
      "metadata": {
        "id": "ZT-uhayxeicX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Loading the data to memory and greyscaling the images"
      ],
      "metadata": {
        "id": "OA3rGqRHZoqn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load images from the disk\n",
        "train_imgs, train_labels = read_imgs('/content/CIFAR10/train/')\n",
        "test_imgs, test_labels = read_imgs('/content/CIFAR10/test/')\n",
        "\n",
        "# Greyscale the rgb images\n",
        "grey_train_imgs = rgb2grey(train_imgs)\n",
        "grey_test_imgs = rgb2grey(test_imgs)\n",
        "\n",
        "# Normalise the greyscaled images\n",
        "grey_train_imgs = normalise(grey_train_imgs)\n",
        "grey_test_imgs = normalise(grey_test_imgs)\n",
        "\n",
        "# Flatten the image matrices to vectors\n",
        "grey_train_imgs = grey_train_imgs.reshape(-1, 1024, 1)\n",
        "grey_test_imgs = grey_test_imgs.reshape(-1, 1024, 1)\n",
        "\n",
        "# Select a limited set of data\n",
        "actual_train_imgs, actual_train_labels = shuffle_data(grey_train_imgs, train_labels)\n",
        "\n",
        "costs = np.zeros((epochs,), dtype=float)\n",
        "corrects = np.zeros((epochs,), dtype=float)"
      ],
      "metadata": {
        "id": "jtJsxQxI1cpy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Starting the algorithm\n",
        "Repeating the algorithm 10 times"
      ],
      "metadata": {
        "id": "pMkhZflZaLN-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "repetitions = 10\n",
        "for _ in range(repetitions):\n",
        "\n",
        "  # Initialise the network basic configurations - weights and biases\n",
        "  w, b = initialise_network()\n",
        "\n",
        "  # Process the input data\n",
        "  for i in range(epochs):\n",
        "    \n",
        "    correct_guesses = 0\n",
        "    costs_total = 0\n",
        "    \n",
        "    # Shuffle the input data\n",
        "    actual_train_imgs, actual_train_labels = shuffle_data(actual_train_imgs, actual_train_labels)\n",
        "    \n",
        "    for j in range(0, n_actual, batch_size):\n",
        "      \n",
        "      # Break the input data into batches\n",
        "      batch_imgs = actual_train_imgs[j : j + batch_size]\n",
        "      batch_labels = actual_train_labels[j : j + batch_size]\n",
        "      gw, gb = initialise_gradients()\n",
        "\n",
        "      for img, label in zip(batch_imgs, batch_labels):\n",
        "\n",
        "        # Compute the network output for the current image\n",
        "        o, z = feed_forward(img, w, b)\n",
        "        costs_total += np.sum((o[2] - label) ** 2)\n",
        "\n",
        "        # Backpropagate the error to update the weights and biases    \n",
        "        grad_w0, grad_b0, grad_w1, grad_b1, grad_w2, grad_b2 = back_propagate(o, z, w, b, img, label)\n",
        "        gw[0] += grad_w0\n",
        "        gw[1] += grad_w1\n",
        "        gw[2] += grad_w2\n",
        "        gb[0] += grad_b0\n",
        "        gb[1] += grad_b1\n",
        "        gb[2] += grad_b2\n",
        "        \n",
        "        # Check if the model had predicted the current image correctly\n",
        "        if np.argmax(o[2]) == np.argmax(label):\n",
        "          correct_guesses += 1\n",
        "    \n",
        "      # Update weights and biases\n",
        "      coef = learning_rate / batch_size\n",
        "      for r in range(3):\n",
        "        w[r] -= coef * gw[r]\n",
        "        b[r] -= coef * gb[r]\n",
        "\n",
        "    # Record corrects and costs\n",
        "    corrects[i] += correct_guesses\n",
        "    costs[i] += costs_total"
      ],
      "metadata": {
        "id": "LqfjZ-l_MxnE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Output the results for accuracy and loss respectively\n",
        "For the vectorised version, the accuracy rises to above 50% after 40 epochs and the cost falls under 0.6."
      ],
      "metadata": {
        "id": "Eo4FGG3GauYv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.linspace(0, epochs, num=epochs, endpoint=False, dtype=int)\n",
        "coef = repetitions * n_actual\n",
        "corrects /= coef\n",
        "costs /= coef\n",
        "\n",
        "pyplot.subplot(2, 1, 1)\n",
        "pyplot.plot(x, corrects, title='Accuracy')\n",
        "\n",
        "pyplot.subplot(2, 1, 2)\n",
        "pyplot.plot(x, costs, title='Loss')"
      ],
      "metadata": {
        "id": "9TbXpG1n3Grs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "4e6e0127-32a0-4f64-992f-b02eabda802e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f5066ede150>]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Accuracy of the unvectorised model:\n",
        "The unvectorised version of the model runs on average for 30s to process 800 input images of 4 classes.\n",
        "The accuracy of such a model can vary between 28% to 31%."
      ],
      "metadata": {
        "id": "dM4Y51iNb2iM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Accuracy of the vectorised model:\n",
        "The vectorised version of the model runs on average for 3 minutes to process 20000 input images of 4 classes.\n",
        "The accuracy of such a model can rise up to 55%."
      ],
      "metadata": {
        "id": "JHkrrm75oYES"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing the model on test images\n",
        "The accuracy of the model on test data runs around 53-55%."
      ],
      "metadata": {
        "id": "UciJ3ZvFc1n6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = 0\n",
        "test_cost = 0\n",
        "for img, label in zip(grey_test_imgs, test_labels):\n",
        "  o, z = feed_forward(img, w, b)\n",
        "  if np.argmax(o[2]) == np.argmax(label):\n",
        "    accuracy += 1\n",
        "  test_cost += np.sum((o[2] - label) ** 2)\n",
        "\n",
        "accuracy /= n_test_samples\n",
        "test_cost /= n_test_samples\n",
        "\n",
        "print('Validation Accuracy: {}'.format(accuracy))\n",
        "print('Validation Loss: {}'.format(test_cost))"
      ],
      "metadata": {
        "id": "DKrEMM5NmwMu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4127be61-de2d-4b1d-8198-24c84563a8b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 0.5415\n",
            "Validation Loss: 1.7441909542281724\n"
          ]
        }
      ]
    }
  ]
}